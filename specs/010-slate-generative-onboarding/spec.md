# Specification: SLATE Generative Onboarding UI

**Spec ID**: 010-slate-generative-onboarding
**Status**: completed
**Created**: 2026-02-07
**Author**: Claude Opus 4.5

## Overview

Full GUI development for the SLATE VSCode extension with AI-driven generative onboarding, brochure-style UI, and automated install processes powered by local Ollama inference.

## Goals

1. **Brochure-Style Hero** - Product-quality landing experience in VSCode sidebar
2. **7-Step Guided Install** - Automated system setup with zero user decisions
3. **AI Narration** - Real-time AI-generated guidance via local Ollama
4. **Generative Components** - Dynamic UI based on system state
5. **Design Token Alignment** - Consistent with spec-007 engineering theme

## Architecture

### VSCode Extension Components

| Component | File | Description |
|-----------|------|-------------|
| GuidedInstallWebview | `slateGuidedInstallView.ts` | Main onboarding UI |
| ControlBoard | `slateControlBoardView.ts` | Dev cycle + learning |
| Dashboard | `slateDashboardView.ts` | FastAPI iframe embed |

### Python Backend

| Module | Description |
|--------|-------------|
| `slate_generative_ui.py` | AI narration + system analysis |
| `guided_workflow.py` | Step execution engine |
| `guided_mode.py` | State management |

## Design System (Spec 007 Alignment)

### Color Palette

```css
/* Primary Brand */
--slate-primary: #B85A3C;         /* Anthropic-inspired warm rust */
--slate-primary-light: #D4785A;
--slate-primary-dark: #8B4530;

/* Blueprint Engineering */
--blueprint-bg: #0D1B2A;          /* Deep technical blue */
--blueprint-grid: #1B3A4B;        /* Subtle grid lines */
--blueprint-accent: #98C1D9;      /* Highlight color */
--blueprint-node: #E0FBFC;        /* Node backgrounds */

/* Status Semantics */
--status-active: #22C55E;         /* Green - connected/running */
--status-pending: #F59E0B;        /* Amber - in progress */
--status-error: #EF4444;          /* Red - failed/error */
```

### Typography

```css
--font-display: 'Segoe UI', 'Inter', system-ui, sans-serif;
--font-mono: 'Cascadia Code', 'JetBrains Mono', 'Consolas', monospace;
```

## Guided Install Flow

### 7 Steps

```
1. WELCOME          â†’ Hero display, value proposition
2. SYSTEM SCAN      â†’ Detect Python, GPU, Ollama, Docker, GitHub
3. CORE SERVICES    â†’ Configure venv, deps, dashboard, orchestrator
4. AI BACKENDS      â†’ Verify Ollama, check models, test inference
5. INTEGRATIONS     â†’ GitHub auth, Docker, MCP server, runner
6. VALIDATION       â†’ Health check, GPU access, workflow test
7. COMPLETE         â†’ Summary, AI recommendations, next steps
```

### AI Narration Examples

Generated by local Ollama (mistral-nemo):

**Welcome:**
> "Hello Developer! Welcome to your new AI playground. No cloud costs here - let's rock with dual GPU power!"

**AI Backends:**
> "Exciting news! Configuring Ollama for local AI means you can now run powerful models locally, avoiding API costs while keeping all the capabilities!"

**Complete:**
> "Congratulations! Your SLATE system is fully operational. Try '@slate /run' in VS Code to get started!"

## UI Components

### Hero Section

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        âœ· Starburst Logo âœ·                       â”‚
â”‚                                                                 â”‚
â”‚                       S . L . A . T . E .                       â”‚
â”‚             Synchronized Living Architecture for                â”‚
â”‚               Transformation and Evolution                      â”‚
â”‚                                                                 â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚        â”‚ 2x GPU   â”‚    â”‚ 100%     â”‚    â”‚ $0       â”‚           â”‚
â”‚        â”‚ 5070 Ti  â”‚    â”‚ Local AI â”‚    â”‚ Cloud    â”‚           â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                 â”‚
â”‚               [  Start Guided Setup  ]                          â”‚
â”‚               [    Advanced Mode     ]                          â”‚
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚    â”‚  ðŸ§  AI â”‚  â”‚  âš¡GPU  â”‚  â”‚ ðŸ¤–Agentâ”‚  â”‚ ðŸ“¦ CI  â”‚             â”‚
â”‚    â”‚ Local  â”‚  â”‚  Dual  â”‚  â”‚ Agenticâ”‚  â”‚ Runner â”‚             â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Guided Mode Overlay

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—‹â”€â”€â”€â”€â—‹â”€â”€â”€â”€â—‹      Step 4 of 7            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚  ðŸ¤–  â”‚  "Exciting news! Configuring Ollama for local AI..."  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AI Backends                                    [Executing]      â”‚
â”‚  Setting up local AI inference                                  â”‚
â”‚                                                                 â”‚
â”‚  â— Verify Ollama connection          Ollama connected          â”‚
â”‚  âœ“ Check installed models            5 models available        â”‚
â”‚  â—‹ Ensure mistral-nemo available                                â”‚
â”‚  â—‹ Test inference endpoint                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             [Skip]                    [Exit]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Generative UI Engine

### System Analysis

```python
@dataclass
class SystemAnalysis:
    python_version: Optional[str]
    gpu_count: int
    gpu_models: List[str]
    total_vram_gb: float
    ollama_available: bool
    ollama_models: List[str]
    docker_available: bool
    github_authenticated: bool
    recommendations: List[str]
```

### AI Narration

```python
async def generate_narration(step: OnboardingStep) -> str:
    """Generate AI narration via local Ollama."""
    prompt = f"Generate a brief, encouraging message for {step.title}..."
    response = await query_ollama(prompt, model="mistral-nemo")
    return response or fallback_narration[step]
```

### Animation Hints

| Step | Animations |
|------|------------|
| Welcome | pulse-logo, fade-in-title, slide-up-cta |
| System Scan | scan-wave, detect-pulse, check-appear |
| Core Services | config-spin, service-stack, connect-lines |
| AI Backends | brain-pulse, model-load, inference-flow |
| Integrations | link-connect, sync-arrows, api-pulse |
| Validation | check-cascade, green-wave, success-burst |
| Complete | celebration-burst, confetti, glow-pulse |

## Files Created

### TypeScript (VSCode Extension)

| File | Lines | Description |
|------|-------|-------------|
| `slateGuidedInstallView.ts` | ~800 | Full guided install webview |

### Python (Backend)

| File | Lines | Description |
|------|-------|-------------|
| `slate_generative_ui.py` | ~450 | Generative UI engine |

### Package.json Updates

- Added `slate.guidedInstall` view to sidebar
- Registered above Control Board and Dashboard

## Testing

### TypeScript Compilation

```bash
cd plugins/slate-copilot && npm run compile
# Compiles without errors
```

### System Analysis

```bash
python slate/slate_generative_ui.py --analyze-system
# Python: Python 3.11.9
# GPUs: 2 (NVIDIA GeForce RTX 5070 Ti, NVIDIA GeForce RTX 5070 Ti)
# VRAM: 31.8 GB
# Ollama: Available
# Models: slate-planner, slate-fast, slate-coder, llama3.2, nomic-embed-text
# Docker: Available
# GitHub: Authenticated
```

### AI Narration

```bash
python slate/slate_generative_ui.py --narrate welcome
# [welcome] "Hello Developer! Welcome to your new AI playground..."
```

## Success Metrics

1. **Zero-Click Install** - User clicks "Start Guided Setup" and system configures itself
2. **AI Narration** - Real-time AI-generated guidance at each step
3. **System Detection** - 100% auto-detection of installed services
4. **Token Efficiency** - AI narration uses local Ollama (zero cloud cost)
5. **Design Consistency** - All UI matches spec-007 engineering theme

## Integration Points

### With Spec 008 (Guided Experience)

- Uses same step flow architecture
- Shares AI narration system
- Inherits brochure UI principles

### With Spec 009 (Roadmap Awareness)

- Guided install sets initial dev cycle stage
- Connects to learning system on completion
- Initializes achievement tracking

### With @slate Participant

- "Start Guided Setup" available via `/install` command
- AI recommendations link to participant commands
- Completion suggests `@slate /run`
