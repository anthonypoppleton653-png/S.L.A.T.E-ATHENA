#!/usr/bin/env python3
# Modified: 2026-02-09T12:39:00-05:00 | Author: Gemini (Antigravity)
# Change: Create SLATE token counter â€” objective AI inference metering
# NOTE: All AIs modifying this file must add a dated comment.
"""
SLATE Token Counter
===================

Objective, always-on metering for all local AI inference operations.
Every Ollama call in the SLATE ecosystem is counted, attributed to an agent,
and persisted to an append-only JSONL ledger.

Features:
- Per-call recording (prompt tokens, completion tokens, duration, GPU, temp)
- Real-time throughput calculation (tok/s rolling average)
- Per-agent attribution
- Energy cost estimation (integrates with energy_scheduler)
- Lifetime cumulative statistics
- Dashboard/CLI/API access

Data is persisted to: .slate_analytics/token_ledger.jsonl
  (append-only, one JSON line per inference call)

Usage:
    from slate.token_counter import TokenCounter

    counter = TokenCounter()
    counter.record(InferenceEvent(...))
    stats = counter.get_throughput("1h")
    lifetime = counter.get_lifetime_stats()

CLI:
    python slate/token_counter.py --today
    python slate/token_counter.py --week
    python slate/token_counter.py --lifetime
    python slate/token_counter.py --live    # live tok/s monitor
"""

import json
import os
import sys
import time
import threading
from collections import deque
from datetime import datetime, timezone, timedelta, date
from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import Dict, List, Optional, Any, Deque

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

WORKSPACE_ROOT = Path(os.environ.get("SLATE_WORKSPACE", Path(__file__).parent.parent))
ANALYTICS_DIR = WORKSPACE_ROOT / ".slate_analytics"
LEDGER_PATH = ANALYTICS_DIR / "token_ledger.jsonl"
STATS_CACHE_PATH = ANALYTICS_DIR / "token_stats_cache.json"

# How many recent events to keep in memory for throughput calculation
THROUGHPUT_BUFFER_SIZE = 1000

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Data Classes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class InferenceEvent:
    """A single AI inference call."""
    timestamp: str                    # ISO 8601
    agent: str                        # "antigravity", "copilot", "claude", "workflow"
    model: str                        # "slate-coder", "slate-fast", "slate-planner"
    prompt_tokens: int                # Tokens sent TO the model
    completion_tokens: int            # Tokens generated BY the model
    duration_ms: int                  # Wall-clock inference time
    gpu_id: int = 0                   # Which GPU served this
    temperature_c: float = 0.0        # GPU temp at time of inference
    energy_cost_usd: float = 0.0      # Estimated electrical cost
    session_id: str = ""              # Grouping key for related calls
    context: str = ""                 # Brief description (e.g., "code review")

    @property
    def total_tokens(self) -> int:
        return self.prompt_tokens + self.completion_tokens

    @property
    def tokens_per_second(self) -> float:
        if self.duration_ms <= 0:
            return 0.0
        return (self.completion_tokens / self.duration_ms) * 1000.0

    def to_ledger_line(self) -> str:
        """Compact JSON line for the ledger."""
        return json.dumps({
            "ts": self.timestamp,
            "agent": self.agent,
            "model": self.model,
            "prompt_tok": self.prompt_tokens,
            "completion_tok": self.completion_tokens,
            "dur_ms": self.duration_ms,
            "gpu": self.gpu_id,
            "temp_c": round(self.temperature_c, 1),
            "cost_usd": round(self.energy_cost_usd, 6),
            "ctx": self.context,
        }, separators=(",", ":"))

    @classmethod
    def from_ledger_line(cls, line: str) -> "InferenceEvent":
        """Parse a ledger JSON line back into an InferenceEvent."""
        d = json.loads(line)
        return cls(
            timestamp=d.get("ts", ""),
            agent=d.get("agent", "unknown"),
            model=d.get("model", "unknown"),
            prompt_tokens=d.get("prompt_tok", 0),
            completion_tokens=d.get("completion_tok", 0),
            duration_ms=d.get("dur_ms", 0),
            gpu_id=d.get("gpu", 0),
            temperature_c=d.get("temp_c", 0.0),
            energy_cost_usd=d.get("cost_usd", 0.0),
            context=d.get("ctx", ""),
        )


@dataclass
class ThroughputReport:
    """Throughput metrics over a time window."""
    window: str
    total_tokens: int = 0
    prompt_tokens: int = 0
    completion_tokens: int = 0
    tokens_per_second: float = 0.0
    tokens_per_minute_avg: float = 0.0
    calls_count: int = 0
    models_used: Dict[str, int] = field(default_factory=dict)
    agents_used: Dict[str, int] = field(default_factory=dict)
    gpu_utilization: Dict[int, float] = field(default_factory=dict)
    energy_cost_usd: float = 0.0
    start_time: str = ""
    end_time: str = ""


@dataclass
class LifetimeStats:
    """All-time cumulative statistics."""
    total_tokens: int = 0
    total_prompt_tokens: int = 0
    total_completion_tokens: int = 0
    total_inference_calls: int = 0
    total_gpu_hours: float = 0.0
    total_energy_cost_usd: float = 0.0
    first_inference: str = ""
    last_inference: str = ""
    busiest_day: str = ""
    busiest_day_tokens: int = 0
    favorite_model: str = ""
    most_active_agent: str = ""
    avg_tokens_per_second: float = 0.0


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Token Counter
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class TokenCounter:
    """
    Objective AI inference metering system.

    Every Ollama call in the SLATE ecosystem is routed through this
    counter. It intercepts the response metadata to extract token
    counts without adding latency to inference.
    """

    def __init__(self, ledger_path: Path = LEDGER_PATH):
        self.ledger_path = ledger_path
        self._lock = threading.Lock()

        # In-memory ring buffer for recent events (throughput calc)
        self._recent_events: Deque[InferenceEvent] = deque(maxlen=THROUGHPUT_BUFFER_SIZE)

        # Running counters (fast path â€” don't read file for these)
        self._session_prompt_tokens = 0
        self._session_completion_tokens = 0
        self._session_calls = 0
        self._session_start = datetime.now(timezone.utc)
        self._session_energy_cost = 0.0

        # Ensure analytics directory
        ANALYTICS_DIR.mkdir(parents=True, exist_ok=True)

    # â”€â”€â”€â”€ Recording â”€â”€â”€â”€

    def record(self, event: InferenceEvent):
        """
        Record a single inference event.

        This is designed to be FAST â€” it appends one line to the ledger
        and updates in-memory counters. No blocking reads.
        """
        with self._lock:
            # Update in-memory counters
            self._session_prompt_tokens += event.prompt_tokens
            self._session_completion_tokens += event.completion_tokens
            self._session_calls += 1
            self._session_energy_cost += event.energy_cost_usd
            self._recent_events.append(event)

        # Async-safe disk write (append-only)
        try:
            with open(self.ledger_path, "a", encoding="utf-8") as f:
                f.write(event.to_ledger_line() + "\n")
        except Exception as e:
            print(f"[TokenCounter] Ledger write error: {e}", file=sys.stderr)

    def record_from_ollama_response(self, agent: str, model: str,
                                     response: Dict[str, Any],
                                     gpu_id: int = 0,
                                     context: str = ""):
        """
        Convenience method: record directly from an Ollama API response.

        Extracts prompt_tokens, completion_tokens, duration from the
        Ollama response format.
        """
        # Ollama response format varies by endpoint
        prompt_tok = response.get("prompt_eval_count", 0)
        completion_tok = response.get("eval_count", 0)
        total_duration = response.get("total_duration", 0)  # nanoseconds
        duration_ms = int(total_duration / 1_000_000) if total_duration else 0

        # Get GPU temperature (best effort)
        temp_c = self._get_gpu_temp(gpu_id)

        # Estimate energy cost (if energy scheduler is available)
        cost_usd = self._estimate_energy_cost(duration_ms)

        event = InferenceEvent(
            timestamp=datetime.now(timezone.utc).isoformat(),
            agent=agent,
            model=model,
            prompt_tokens=prompt_tok,
            completion_tokens=completion_tok,
            duration_ms=duration_ms,
            gpu_id=gpu_id,
            temperature_c=temp_c,
            energy_cost_usd=cost_usd,
            context=context,
        )
        self.record(event)
        return event

    # â”€â”€â”€â”€ Throughput â”€â”€â”€â”€

    def get_throughput(self, window: str = "1h") -> ThroughputReport:
        """
        Calculate throughput metrics over a time window.

        Supported windows: "5m", "15m", "1h", "6h", "24h"
        """
        window_minutes = {
            "5m": 5, "15m": 15, "1h": 60, "6h": 360, "24h": 1440,
        }.get(window, 60)

        cutoff = datetime.now(timezone.utc) - timedelta(minutes=window_minutes)
        cutoff_iso = cutoff.isoformat()

        report = ThroughputReport(window=window)
        models: Dict[str, int] = {}
        agents: Dict[str, int] = {}
        gpu_time: Dict[int, float] = {}
        total_duration_ms = 0

        with self._lock:
            for event in self._recent_events:
                if event.timestamp >= cutoff_iso:
                    report.total_tokens += event.total_tokens
                    report.prompt_tokens += event.prompt_tokens
                    report.completion_tokens += event.completion_tokens
                    report.calls_count += 1
                    report.energy_cost_usd += event.energy_cost_usd
                    total_duration_ms += event.duration_ms

                    models[event.model] = models.get(event.model, 0) + event.total_tokens
                    agents[event.agent] = agents.get(event.agent, 0) + event.total_tokens
                    gpu_time[event.gpu_id] = gpu_time.get(event.gpu_id, 0) + event.duration_ms

        report.models_used = models
        report.agents_used = agents

        # Throughput
        if total_duration_ms > 0:
            report.tokens_per_second = (
                report.completion_tokens / total_duration_ms
            ) * 1000.0

        window_seconds = window_minutes * 60
        if window_seconds > 0:
            report.tokens_per_minute_avg = report.total_tokens / window_minutes

        # GPU utilization (% of window spent on inference per GPU)
        for gpu_id, dur_ms in gpu_time.items():
            report.gpu_utilization[gpu_id] = min(
                100.0, (dur_ms / (window_minutes * 60 * 1000)) * 100
            )

        report.start_time = cutoff.isoformat()
        report.end_time = datetime.now(timezone.utc).isoformat()

        return report

    def get_current_tps(self) -> float:
        """Get the current tokens-per-second (last 30 seconds rolling average)."""
        cutoff = (datetime.now(timezone.utc) - timedelta(seconds=30)).isoformat()
        total_completion = 0
        total_duration_ms = 0

        with self._lock:
            for event in reversed(self._recent_events):
                if event.timestamp < cutoff:
                    break
                total_completion += event.completion_tokens
                total_duration_ms += event.duration_ms

        if total_duration_ms <= 0:
            return 0.0
        return (total_completion / total_duration_ms) * 1000.0

    # â”€â”€â”€â”€ Session Stats â”€â”€â”€â”€

    def get_session_stats(self) -> Dict[str, Any]:
        """Get current session statistics."""
        total = self._session_prompt_tokens + self._session_completion_tokens
        elapsed = (datetime.now(timezone.utc) - self._session_start).total_seconds()

        return {
            "session_start": self._session_start.isoformat(),
            "elapsed_minutes": round(elapsed / 60, 1),
            "prompt_tokens": self._session_prompt_tokens,
            "completion_tokens": self._session_completion_tokens,
            "total_tokens": total,
            "inference_calls": self._session_calls,
            "energy_cost_usd": round(self._session_energy_cost, 4),
            "current_tps": round(self.get_current_tps(), 1),
        }

    # â”€â”€â”€â”€ Lifetime Stats â”€â”€â”€â”€

    def get_lifetime_stats(self) -> LifetimeStats:
        """
        Compute all-time cumulative statistics from the ledger.

        Note: This reads the entire ledger file â€” use sparingly.
        For frequent access, use get_session_stats() or get_throughput().
        """
        stats = LifetimeStats()
        daily_tokens: Dict[str, int] = {}
        model_counts: Dict[str, int] = {}
        agent_counts: Dict[str, int] = {}
        total_duration_ms = 0

        if not self.ledger_path.exists():
            return stats

        try:
            with open(self.ledger_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        event = InferenceEvent.from_ledger_line(line)
                    except Exception:
                        continue

                    stats.total_prompt_tokens += event.prompt_tokens
                    stats.total_completion_tokens += event.completion_tokens
                    stats.total_tokens += event.total_tokens
                    stats.total_inference_calls += 1
                    stats.total_energy_cost_usd += event.energy_cost_usd
                    total_duration_ms += event.duration_ms

                    if not stats.first_inference or event.timestamp < stats.first_inference:
                        stats.first_inference = event.timestamp
                    if not stats.last_inference or event.timestamp > stats.last_inference:
                        stats.last_inference = event.timestamp

                    # Daily aggregation
                    day = event.timestamp[:10]
                    daily_tokens[day] = daily_tokens.get(day, 0) + event.total_tokens

                    # Model/agent counts
                    model_counts[event.model] = model_counts.get(event.model, 0) + event.total_tokens
                    agent_counts[event.agent] = agent_counts.get(event.agent, 0) + event.total_tokens
        except Exception as e:
            print(f"[TokenCounter] Ledger read error: {e}", file=sys.stderr)

        # Derived stats
        if total_duration_ms > 0:
            stats.total_gpu_hours = total_duration_ms / (1000 * 3600)
            stats.avg_tokens_per_second = (
                stats.total_completion_tokens / total_duration_ms
            ) * 1000.0

        if daily_tokens:
            busiest = max(daily_tokens.items(), key=lambda x: x[1])
            stats.busiest_day = busiest[0]
            stats.busiest_day_tokens = busiest[1]

        if model_counts:
            stats.favorite_model = max(model_counts.items(), key=lambda x: x[1])[0]
        if agent_counts:
            stats.most_active_agent = max(agent_counts.items(), key=lambda x: x[1])[0]

        stats.total_energy_cost_usd = round(stats.total_energy_cost_usd, 4)

        return stats

    def get_daily_stats(self, target_date: date = None) -> Dict[str, Any]:
        """Get statistics for a specific day (defaults to today)."""
        if target_date is None:
            target_date = datetime.now(timezone.utc).date()
        day_prefix = target_date.isoformat()

        total_tokens = 0
        prompt_tokens = 0
        completion_tokens = 0
        calls = 0
        cost = 0.0
        agents: Dict[str, int] = {}
        models: Dict[str, int] = {}

        if not self.ledger_path.exists():
            return {"date": day_prefix, "total_tokens": 0, "calls": 0}

        try:
            with open(self.ledger_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        d = json.loads(line)
                    except Exception:
                        continue

                    if not d.get("ts", "").startswith(day_prefix):
                        continue

                    pt = d.get("prompt_tok", 0)
                    ct = d.get("completion_tok", 0)
                    prompt_tokens += pt
                    completion_tokens += ct
                    total_tokens += pt + ct
                    calls += 1
                    cost += d.get("cost_usd", 0)
                    ag = d.get("agent", "unknown")
                    agents[ag] = agents.get(ag, 0) + pt + ct
                    mod = d.get("model", "unknown")
                    models[mod] = models.get(mod, 0) + pt + ct
        except Exception:
            pass

        return {
            "date": day_prefix,
            "total_tokens": total_tokens,
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "calls": calls,
            "energy_cost_usd": round(cost, 4),
            "agents": agents,
            "models": models,
        }

    # â”€â”€â”€â”€ Helpers â”€â”€â”€â”€

    def _get_gpu_temp(self, gpu_id: int = 0) -> float:
        """Best-effort GPU temperature reading."""
        try:
            import subprocess
            result = subprocess.run(
                ["nvidia-smi", "--query-gpu=temperature.gpu",
                 "--format=csv,noheader,nounits", f"--id={gpu_id}"],
                capture_output=True, text=True, timeout=2
            )
            if result.returncode == 0:
                return float(result.stdout.strip())
        except Exception:
            pass
        return 0.0

    def _estimate_energy_cost(self, duration_ms: int) -> float:
        """
        Estimate electrical cost for an inference call.

        Uses the energy scheduler config if available, otherwise
        estimates based on default GPU power draw.
        """
        try:
            import yaml
            energy_path = WORKSPACE_ROOT / ".slate_config" / "energy.yaml"
            if energy_path.exists():
                with open(energy_path, "r", encoding="utf-8") as f:
                    config = yaml.safe_load(f)
                energy = config.get("energy", {})
                if not energy.get("enabled", False):
                    return 0.0

                # Get current rate
                power_draw = energy.get("power_draw", {})
                watts = power_draw.get("single_gpu_inference", 250)
                rates = energy.get("provider", {}).get("rates", {})

                # Determine current rate tier
                hour = datetime.now().hour
                cost_per_kwh = 0.10  # Default fallback
                for tier_name, tier_data in rates.items():
                    if isinstance(tier_data, dict) and hour in tier_data.get("hours", []):
                        cost_per_kwh = tier_data.get("cost_per_kwh", 0.10)
                        break

                # kWh = watts * hours
                hours = (duration_ms / 1000) / 3600
                kwh = (watts / 1000) * hours
                return kwh * cost_per_kwh
        except Exception:
            pass

        # Fallback: 250W GPU, $0.10/kWh
        hours = (duration_ms / 1000) / 3600
        kwh = 0.25 * hours
        return kwh * 0.10


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _format_number(n: int) -> str:
    """Human-readable number formatting."""
    if n >= 1_000_000:
        return f"{n / 1_000_000:.1f}M"
    elif n >= 1_000:
        return f"{n / 1_000:.1f}K"
    return str(n)


def main():
    """CLI: slate tokens [--today|--week|--lifetime|--live]"""
    import argparse
    parser = argparse.ArgumentParser(description="SLATE Token Counter CLI")
    parser.add_argument("--today", action="store_true", help="Show today's stats")
    parser.add_argument("--week", action="store_true", help="Show last 7 days")
    parser.add_argument("--lifetime", action="store_true", help="Show lifetime stats")
    parser.add_argument("--live", action="store_true", help="Live throughput monitor")
    parser.add_argument("--json", action="store_true", help="JSON output")

    args = parser.parse_args()
    counter = TokenCounter()

    if args.today:
        stats = counter.get_daily_stats()
        if args.json:
            print(json.dumps(stats, indent=2))
        else:
            print(f"\n  ðŸ“Š SLATE Token Counter â€” {stats['date']}")
            print(f"  {'â”€' * 45}")
            print(f"  Total tokens:      {_format_number(stats['total_tokens'])}")
            print(f"  Prompt tokens:     {_format_number(stats['prompt_tokens'])}")
            print(f"  Completion tokens: {_format_number(stats['completion_tokens'])}")
            print(f"  Inference calls:   {stats['calls']}")
            print(f"  Energy cost:       ${stats['energy_cost_usd']:.4f}")
            if stats.get('agents'):
                print(f"\n  Per-Agent:")
                for agent, tok in sorted(stats['agents'].items(), key=lambda x: -x[1]):
                    pct = (tok / max(stats['total_tokens'], 1)) * 100
                    bar = "â–ˆ" * int(pct / 5) + "â–‘" * (20 - int(pct / 5))
                    print(f"    {agent:15s} {bar} {pct:4.0f}%  ({_format_number(tok)})")
            print()

    elif args.lifetime:
        stats = counter.get_lifetime_stats()
        if args.json:
            print(json.dumps(asdict(stats), indent=2))
        else:
            print(f"\n  ðŸ“Š SLATE Token Counter â€” Lifetime")
            print(f"  {'â”€' * 45}")
            print(f"  Total tokens:    {_format_number(stats.total_tokens)}")
            print(f"  Inference calls: {_format_number(stats.total_inference_calls)}")
            print(f"  GPU hours:       {stats.total_gpu_hours:.1f}h")
            print(f"  Energy cost:     ${stats.total_energy_cost_usd:.2f}")
            print(f"  First inference: {stats.first_inference[:19] if stats.first_inference else 'N/A'}")
            print(f"  Last inference:  {stats.last_inference[:19] if stats.last_inference else 'N/A'}")
            print(f"  Busiest day:     {stats.busiest_day} ({_format_number(stats.busiest_day_tokens)})")
            print(f"  Favorite model:  {stats.favorite_model or 'N/A'}")
            print(f"  Top agent:       {stats.most_active_agent or 'N/A'}")
            print(f"  Avg throughput:  {stats.avg_tokens_per_second:.1f} tok/s")
            print()

    elif args.week:
        print(f"\n  ðŸ“Š SLATE Token Counter â€” Last 7 Days")
        print(f"  {'â”€' * 55}")
        today = datetime.now(timezone.utc).date()
        week_total = 0
        for i in range(6, -1, -1):
            d = today - timedelta(days=i)
            stats = counter.get_daily_stats(d)
            tok = stats['total_tokens']
            week_total += tok
            bar = "â–ˆ" * min(30, int(tok / max(1, 1000))) + "â–‘" * max(0, 30 - int(tok / max(1, 1000)))
            label = "TODAY" if i == 0 else d.strftime("%a")
            print(f"  {label:5s} {d.isoformat()} {bar} {_format_number(tok):>7s}")
        print(f"  {'â”€' * 55}")
        print(f"  Weekly total: {_format_number(week_total)}")
        print()

    elif args.live:
        print(f"\n  âš¡ SLATE Live Throughput Monitor (Ctrl+C to stop)")
        print(f"  {'â”€' * 45}")
        try:
            while True:
                tps = counter.get_current_tps()
                session = counter.get_session_stats()
                bar_len = min(40, int(tps))
                bar = "â–ˆ" * bar_len + "â–‘" * (40 - bar_len)
                sys.stdout.write(
                    f"\r  {bar} {tps:5.1f} tok/s | "
                    f"Session: {_format_number(session['total_tokens'])} tok | "
                    f"Calls: {session['inference_calls']}"
                )
                sys.stdout.flush()
                time.sleep(1)
        except KeyboardInterrupt:
            print("\n  Stopped.")

    else:
        # Default: show session stats
        session = counter.get_session_stats()
        if args.json:
            print(json.dumps(session, indent=2))
        else:
            print(f"\n  ðŸ“Š SLATE Token Counter â€” Current Session")
            print(f"  {'â”€' * 45}")
            print(f"  Started:           {session['session_start'][:19]}")
            print(f"  Elapsed:           {session['elapsed_minutes']} min")
            print(f"  Total tokens:      {_format_number(session['total_tokens'])}")
            print(f"  Prompt tokens:     {_format_number(session['prompt_tokens'])}")
            print(f"  Completion tokens: {_format_number(session['completion_tokens'])}")
            print(f"  Inference calls:   {session['inference_calls']}")
            print(f"  Current tok/s:     {session['current_tps']}")
            print(f"  Energy cost:       ${session['energy_cost_usd']:.4f}")
            print()


if __name__ == "__main__":
    main()
