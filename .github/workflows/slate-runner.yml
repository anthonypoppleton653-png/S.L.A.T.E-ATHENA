# ═══════════════════════════════════════════════════════════════════════════════
# SLATE Self-Hosted Runner — Full System Validation
# Modified: 2026-02-09T08:30:00Z | Author: COPILOT | Change: Dual-GPU awareness, SLATE Live System job
# ═══════════════════════════════════════════════════════════════════════════════
# Runs the complete SLATE system stack on the self-hosted runner to validate
# GPU acceleration, ML pipelines, agent systems, and SDK integrity.
#
# Triggers: push to main branches, manual dispatch, nightly schedule
# Target: self-hosted runner with labels [self-hosted, slate, gpu, windows]
# ═══════════════════════════════════════════════════════════════════════════════

name: "SLATE Runner: Full System"

on:
  push:
    branches: [main, "001-data-viz-dashboard"]
    paths:
      - "slate/**"
      - "agents/**"
      - "tests/**"
      - "requirements.txt"
      - "pyproject.toml"
  workflow_dispatch:
    inputs:
      run_gpu_benchmarks:
        description: "Run GPU benchmarks (slower)"
        required: false
        type: boolean
        default: false
      run_ml_pipeline:
        description: "Run ML training pipeline"
        required: false
        type: boolean
        default: false
  schedule:
    - cron: "0 4 * * *"  # 4 AM UTC daily

env:
  SLATE_WORKSPACE: ${{ github.workspace }}
  SLATE_RUNNER: "true"
  PYTHONIOENCODING: "utf-8"

jobs:
  # ─── Environment Validation ───────────────────────────────────────────────
  environment:
    name: "Validate SLATE Environment"
    runs-on: [self-hosted, slate, gpu, windows]
    timeout-minutes: 10
    outputs:
      gpu_available: ${{ steps.gpu.outputs.available }}
      gpu_count: ${{ steps.gpu.outputs.count }}
      slate_version: ${{ steps.sdk.outputs.version }}
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          # Self-heal: ensure workspace directory exists for checkout
          $ws = "${{ github.workspace }}"
          if (-not (Test-Path $ws)) {
            New-Item -ItemType Directory -Path $ws -Force | Out-Null
            Write-Host "Created workspace: $ws"
          } else {
            Write-Host "Workspace ready: $ws"
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: SLATE Environment Check
        id: env
        shell: pwsh
        run: |
          Write-Host "=== SLATE Runner Environment ===" -ForegroundColor Cyan
          Write-Host "Workspace: ${{ github.workspace }}"
          Write-Host "Runner OS: ${{ runner.os }}"
          Write-Host "Runner Arch: ${{ runner.arch }}"

          # Check for SLATE venv
          $venvPython = Join-Path ${{ github.workspace }} ".venv\Scripts\python.exe"
          if (Test-Path $venvPython) {
            Write-Host "SLATE venv: OK ($venvPython)"
            & $venvPython --version
          } else {
            Write-Host "SLATE venv: Not found, using system Python"
            python --version
          }

      - name: GPU Detection
        id: gpu
        shell: pwsh
        run: |
          try {
            $gpuInfo = & nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv,noheader 2>$null
            if ($LASTEXITCODE -eq 0 -and $gpuInfo) {
              $gpuCount = ($gpuInfo -split "`n" | Where-Object { $_.Trim() }).Count
              Write-Host "GPUs detected: $gpuCount"
              $gpuInfo -split "`n" | ForEach-Object { Write-Host "  - $_" }
              echo "available=true" >> $env:GITHUB_OUTPUT
              echo "count=$gpuCount" >> $env:GITHUB_OUTPUT
            } else {
              echo "available=false" >> $env:GITHUB_OUTPUT
              echo "count=0" >> $env:GITHUB_OUTPUT
            }
          } catch {
            echo "available=false" >> $env:GITHUB_OUTPUT
            echo "count=0" >> $env:GITHUB_OUTPUT
          }

      - name: CUDA Toolkit Check
        if: steps.gpu.outputs.available == 'true'
        shell: pwsh
        run: |
          try {
            & nvcc --version 2>$null
            if ($LASTEXITCODE -ne 0) {
              Write-Host "CUDA toolkit not in PATH (nvidia-smi available, nvcc not found)"
            }
          } catch {
            Write-Host "nvcc not available"
          }

      - name: SDK Version
        id: sdk
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          $version = & $python -c "import slate; print(getattr(slate, '__version__', 'unknown'))" 2>$null
          if ($LASTEXITCODE -eq 0) {
            Write-Host "SLATE SDK: v$version"
            echo "version=$version" >> $env:GITHUB_OUTPUT
          } else {
            Write-Host "SDK not importable"
            echo "version=unknown" >> $env:GITHUB_OUTPUT
          }

  # ─── Core System Tests ────────────────────────────────────────────────────
  core-systems:
    name: "Core SLATE Systems"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    timeout-minutes: 15
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: SLATE Status
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python slate/slate_status.py --quick
          if ($LASTEXITCODE -ne 0) {
            Write-Host "::warning::slate_status.py returned non-zero"
          }

      - name: SLATE Runtime Check
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python slate/slate_runtime.py --check-all
          if ($LASTEXITCODE -ne 0) {
            Write-Host "::warning::slate_runtime.py returned non-zero"
          }

      - name: SDK Import Validation
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import slate
          from slate import slate_status
          from slate import slate_runtime
          print('Core SDK imports: OK')

          # Test runner manager
          from slate.slate_runner_manager import SlateRunnerManager
          mgr = SlateRunnerManager()
          status = mgr.get_status()
          print(f'Runner status: installed={status[\"installed\"]}, provisioned={status[\"provisioned\"]}')
          print(f'GPU: {status[\"gpu\"][\"gpu_count\"]} detected')
          print(f'Labels: {status[\"labels\"]}')
          "@

      - name: Hardware Optimizer
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "slate/slate_hardware_optimizer.py") {
            & $python slate/slate_hardware_optimizer.py 2>$null
            if ($LASTEXITCODE -ne 0) {
              Write-Host "::warning::Hardware optimizer returned non-zero"
            }
          } else {
            Write-Host "Hardware optimizer not found, skipping"
          }

      - name: Tech Tree Status
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path ".slate_tech_tree/tech_tree.json") {
            & $python -c @"
          import json
          with open('.slate_tech_tree/tech_tree.json') as f:
              tree = json.load(f)
          total = len(tree) if isinstance(tree, list) else len(tree.get('nodes', tree.get('tasks', [])))
          print(f'Tech tree: {total} nodes loaded')
          "@
          } else {
            Write-Host "Tech tree not found"
          }

  # ─── Dashboard & API ──────────────────────────────────────────────────────
  dashboard:
    name: "Dashboard & API"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    timeout-minutes: 10
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: Dashboard Import Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          try:
              from agents.slate_dashboard_server import app
              print('Dashboard server: importable')
          except ImportError as e:
              print(f'Dashboard import warning: {e}')
          "@

      - name: Dashboard Smoke Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import asyncio, sys
          try:
              from agents.slate_dashboard_server import app
              from fastapi.testclient import TestClient
              client = TestClient(app)
              resp = client.get('/api/status')
              if resp.status_code == 200:
                  print(f'Dashboard API /api/status: {resp.status_code} OK')
              else:
                  print(f'Dashboard API /api/status: {resp.status_code}')
          except Exception as e:
              print(f'Dashboard smoke test skipped: {e}')
          "@

      - name: Install API Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          try:
              from agents.install_api import app
              print('Install API: importable')
          except Exception as e:
              print(f'Install API: {e}')
          "@

  # ─── Agent System ─────────────────────────────────────────────────────────
  agents:
    name: "Agent System Validation"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: core-systems
    timeout-minutes: 15
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: Agent Module Imports
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          modules = [
              'slate.slate_status',
              'slate.slate_runtime',
              'slate.slate_runner_manager',
              'slate.slate_hardware_optimizer',
              'slate.slate_benchmark',
              'slate.slate_fork_manager',
          ]
          ok = 0
          for mod in modules:
              try:
                  __import__(mod)
                  print(f'  OK  {mod}')
                  ok += 1
              except Exception as e:
                  print(f'  SKIP {mod}: {e}')
          print(f'\nAgent modules: {ok}/{len(modules)} importable')
          "@

      - name: Task System Check
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import json, os
          task_files = ['clean_tasks.json', 'current_tasks.json', 'approval_queue.json']
          for tf in task_files:
              if os.path.exists(tf):
                  with open(tf) as f:
                      data = json.load(f)
                  count = len(data) if isinstance(data, list) else len(data.get('tasks', []))
                  print(f'  {tf}: {count} entries')
              else:
                  print(f'  {tf}: not found')
          "@

  # ─── GPU Tests (Dual-GPU Aware) ────────────────────────────────────────────
  gpu-tests:
    name: "GPU & CUDA Tests (Dual-GPU)"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    if: needs.environment.outputs.gpu_available == 'true'
    timeout-minutes: 20
    env:
      CUDA_VISIBLE_DEVICES: "0,1"
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: Dual-GPU Detection
        shell: pwsh
        run: |
          Write-Host "=== Dual-GPU Environment ===" -ForegroundColor Cyan
          & nvidia-smi --query-gpu=index,name,memory.total,compute_cap --format=csv,noheader
          $gpuCount = (& nvidia-smi --query-gpu=name --format=csv,noheader | Measure-Object -Line).Lines
          Write-Host ""
          Write-Host "Total GPUs: $gpuCount"
          Write-Host "CUDA_VISIBLE_DEVICES: $env:CUDA_VISIBLE_DEVICES"
          if ($gpuCount -lt 2) {
            Write-Host "::warning::Expected 2 GPUs but found $gpuCount"
          }

      - name: PyTorch Dual-GPU Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import sys
          try:
              import torch
              print(f'PyTorch version: {torch.__version__}')
              print(f'CUDA available: {torch.cuda.is_available()}')
              if not torch.cuda.is_available():
                  print('CUDA not available — skipping GPU tests')
                  sys.exit(0)

              gpu_count = torch.cuda.device_count()
              print(f'CUDA version: {torch.version.cuda}')
              print(f'GPU count: {gpu_count}')
              assert gpu_count >= 2, f'Expected 2+ GPUs, found {gpu_count}'

              # Test EACH GPU independently
              for i in range(gpu_count):
                  device = torch.device(f'cuda:{i}')
                  name = torch.cuda.get_device_name(i)
                  props = torch.cuda.get_device_properties(i)
                  mem_gb = props.total_mem / 1e9
                  print(f'  GPU {i}: {name} ({mem_gb:.1f} GB, CC {props.major}.{props.minor})')

                  # Tensor allocation + compute on this GPU
                  t = torch.randn(2000, 2000, device=device)
                  result = torch.mm(t, t)
                  print(f'    Matrix multiply on cuda:{i}: OK ({result.shape})')
                  del t, result

              # Cross-GPU tensor transfer test
              print('  Cross-GPU transfer test...')
              t0 = torch.randn(1000, 1000, device='cuda:0')
              t1 = t0.to('cuda:1')
              assert t1.device.index == 1, 'Transfer to GPU 1 failed'
              result = torch.mm(t1, t1)
              print(f'    cuda:0 -> cuda:1 transfer + compute: OK')
              del t0, t1, result

              torch.cuda.empty_cache()
              print(f'Dual-GPU test PASSED ({gpu_count} GPUs verified)')
          except ImportError:
              print('PyTorch not installed')
          except Exception as e:
              print(f'GPU test error: {e}')
              sys.exit(1)
          "@

      - name: VRAM Status (All GPUs)
        shell: pwsh
        run: |
          Write-Host "=== Per-GPU VRAM ===" -ForegroundColor Cyan
          & nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu,temperature.gpu --format=csv,noheader

      - name: GPU Benchmark
        if: github.event_name == 'workflow_dispatch' && inputs.run_gpu_benchmarks
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "slate/slate_benchmark.py") {
            & $python slate/slate_benchmark.py --json
          }

  # ─── SLATE Live System ────────────────────────────────────────────────────
  # Runs SLATE systems LIVE during CI — dashboard, agents, task processing
  # across both GPUs. This validates that SLATE operates during runner runtime.
  slate-live-system:
    name: "SLATE Live System (Dual-GPU)"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: [core-systems, gpu-tests]
    timeout-minutes: 25
    env:
      CUDA_VISIBLE_DEVICES: "0,1"
      SLATE_RUNNER: "true"
      SLATE_CI_MODE: "true"
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: Verify Dual-GPU Environment
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import os, sys
          print('=== SLATE Live System — GPU Environment ===')
          print(f'CUDA_VISIBLE_DEVICES: {os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"NOT SET\")}')
          print(f'SLATE_RUNNER: {os.environ.get(\"SLATE_RUNNER\", \"NOT SET\")}')

          # Verify both GPUs are accessible
          try:
              import torch
              gpu_count = torch.cuda.device_count()
              for i in range(gpu_count):
                  print(f'  GPU {i}: {torch.cuda.get_device_name(i)}')
                  os.environ[f'SLATE_GPU_{i}'] = torch.cuda.get_device_name(i)
              print(f'SLATE_GPU_COUNT: {gpu_count}')
              assert gpu_count >= 2, f'SLATE Live System requires 2+ GPUs, found {gpu_count}'
          except ImportError:
              print('PyTorch not available — GPU names from nvidia-smi')
          "@

      - name: Start SLATE Dashboard (Background)
        id: dashboard
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          Write-Host "Starting SLATE dashboard in background..." -ForegroundColor Cyan
          $dashProc = Start-Process -FilePath $python -ArgumentList @(
            "-c",
            "from agents.slate_dashboard_server import app; import uvicorn; uvicorn.run(app, host='127.0.0.1', port=8420, log_level='warning')"
          ) -PassThru -NoNewWindow -RedirectStandardOutput "dashboard_stdout.log" -RedirectStandardError "dashboard_stderr.log"
          echo "dashboard_pid=$($dashProc.Id)" >> $env:GITHUB_OUTPUT
          Start-Sleep -Seconds 5
          Write-Host "Dashboard PID: $($dashProc.Id)"

          # Health check
          try {
            $resp = Invoke-WebRequest -Uri "http://127.0.0.1:8420/api/status" -TimeoutSec 10 -ErrorAction Stop
            Write-Host "Dashboard health: $($resp.StatusCode) OK" -ForegroundColor Green
          } catch {
            Write-Host "::warning::Dashboard health check failed: $_"
          }

      - name: SLATE Systems Boot
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          Write-Host "=== Booting SLATE Systems ===" -ForegroundColor Cyan

          # Run SLATE status check
          Write-Host "--- SLATE Status ---"
          & $python slate/slate_status.py --quick
          if ($LASTEXITCODE -ne 0) {
            Write-Host "::warning::slate_status.py returned non-zero"
          }

          # Run SLATE runtime checks
          Write-Host "--- SLATE Runtime ---"
          & $python slate/slate_runtime.py --check-all
          if ($LASTEXITCODE -ne 0) {
            Write-Host "::warning::slate_runtime.py returned non-zero"
          }

          # Hardware optimizer
          if (Test-Path "slate/slate_hardware_optimizer.py") {
            Write-Host "--- Hardware Optimizer ---"
            & $python slate/slate_hardware_optimizer.py 2>$null
          }

      - name: Initialize Agent System
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import json, os, sys
          print('=== SLATE Agent System Init ===')

          # Initialize SLATE runner manager
          try:
              from slate.slate_runner_manager import RunnerManager
              mgr = RunnerManager()
              print(f'Runner manager: initialized')
          except Exception as e:
              print(f'Runner manager: {e}')

          # Initialize SLATE status
          try:
              from slate.slate_status import SlateStatus
              status = SlateStatus()
              print(f'SLATE status: initialized')
          except Exception as e:
              print(f'SLATE status: {e}')

          # Load task queue
          task_count = 0
          for tf in ['clean_tasks.json', 'current_tasks.json']:
              if os.path.exists(tf):
                  with open(tf) as f:
                      data = json.load(f)
                  count = len(data) if isinstance(data, list) else len(data.get('tasks', []))
                  task_count += count
                  print(f'  {tf}: {count} tasks')
          print(f'Total tasks available: {task_count}')
          "@

      - name: Dual-GPU Workload Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          import sys, os, time
          print('=== SLATE Dual-GPU Workload ===')

          try:
              import torch
              import torch.nn as nn

              gpu_count = torch.cuda.device_count()
              assert gpu_count >= 2, f'Need 2+ GPUs, found {gpu_count}'

              # Simulate parallel GPU workload across both GPUs
              print('Running parallel workloads on both GPUs...')
              results = {}
              for gpu_id in range(gpu_count):
                  device = torch.device(f'cuda:{gpu_id}')
                  start = time.time()

                  # Larger matrix multiply to actually exercise the GPU
                  a = torch.randn(4096, 4096, device=device)
                  b = torch.randn(4096, 4096, device=device)
                  c = torch.mm(a, b)
                  torch.cuda.synchronize(device)

                  elapsed = time.time() - start
                  mem_used = torch.cuda.memory_allocated(device) / 1e9
                  results[gpu_id] = {'time': elapsed, 'mem_gb': mem_used}
                  print(f'  GPU {gpu_id}: 4096x4096 matmul in {elapsed:.3f}s, {mem_used:.2f} GB used')
                  del a, b, c

              # Multi-GPU data parallel simulation
              print('Multi-GPU data parallel simulation...')
              model = nn.Sequential(nn.Linear(1024, 2048), nn.ReLU(), nn.Linear(2048, 512))
              if gpu_count >= 2:
                  model = nn.DataParallel(model, device_ids=list(range(gpu_count)))
              model = model.cuda()
              x = torch.randn(64, 1024, device='cuda:0')
              out = model(x)
              print(f'  DataParallel output: {out.shape} (across {gpu_count} GPUs)')
              del model, x, out

              torch.cuda.empty_cache()
              print(f'Dual-GPU workload: PASSED')

          except ImportError:
              print('PyTorch not installed — skipping GPU workload')
          except Exception as e:
              print(f'GPU workload error: {e}')
              sys.exit(1)
          "@

      - name: SLATE Runner Status Report
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -c @"
          from slate.slate_runner_manager import SlateRunnerManager
          import json

          mgr = SlateRunnerManager()
          status = mgr.get_status()

          print('=== SLATE Runner Live Status ===')
          print(f'Installed:    {status[\"installed\"]}')
          print(f'Configured:   {status[\"configured\"]}')
          print(f'Provisioned:  {status[\"provisioned\"]}')
          print(f'Running:      {status[\"running\"]}')
          print(f'GPU Count:    {status[\"gpu\"][\"gpu_count\"]}')
          print(f'GPU Names:    {status[\"gpu\"][\"gpu_names\"]}')
          print(f'Labels:       {status[\"labels\"]}')

          # Verify multi-gpu label is present
          assert 'multi-gpu' in status['labels'], 'multi-gpu label missing!'
          assert 'gpu-2' in status['labels'], 'gpu-2 label missing!'
          print('Label assertions: PASSED')
          "@

      - name: Stop Dashboard
        if: always()
        shell: pwsh
        run: |
          $pid = "${{ steps.dashboard.outputs.dashboard_pid }}"
          if ($pid -and $pid -ne "") {
            Write-Host "Stopping dashboard (PID: $pid)..."
            try { Stop-Process -Id $pid -Force -ErrorAction SilentlyContinue } catch {}
          }
          # Also cleanup any stray uvicorn processes on our port
          $procs = Get-NetTCPConnection -LocalPort 8420 -ErrorAction SilentlyContinue | Select-Object -ExpandProperty OwningProcess -Unique
          foreach ($p in $procs) {
            try { Stop-Process -Id $p -Force -ErrorAction SilentlyContinue } catch {}
          }
          Write-Host "Dashboard cleanup complete"

  # ─── ML Pipeline ──────────────────────────────────────────────────────────
  ml-pipeline:
    name: "ML Pipeline Validation"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: [environment, gpu-tests]
    if: |
      always() &&
      needs.environment.result == 'success' &&
      (github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && inputs.run_ml_pipeline))
    timeout-minutes: 30
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: ML Orchestrator Status
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "slate/ml_orchestrator.py") {
            & $python slate/ml_orchestrator.py --status
          } else {
            Write-Host "ML orchestrator not found"
          }

      - name: ML Index
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "slate/ml_orchestrator.py") {
            & $python slate/ml_orchestrator.py --index-now
          }

      - name: ML Training Cycle
        shell: pwsh
        timeout-minutes: 20
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "slate/ml_orchestrator.py") {
            & $python slate/ml_orchestrator.py --train-now
          }

  # ─── Package Validation ───────────────────────────────────────────────────
  package:
    name: "Package & Build"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: environment
    timeout-minutes: 10
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: Package Build Test
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          & $python -m build --sdist --no-isolation 2>$null
          if ($LASTEXITCODE -eq 0) {
            Write-Host "Package build: OK"
            Get-ChildItem dist/ -Name
          } else {
            Write-Host "::warning::Package build failed (build module may not be installed)"
          }

      - name: Package Manager Validate
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          if (Test-Path "slate/slate_package_manager.py") {
            & $python slate/slate_package_manager.py validate
          }

  # ─── Summary ──────────────────────────────────────────────────────────────
  summary:
    name: "Runner Summary"
    runs-on: [self-hosted, slate, gpu, windows]
    needs: [environment, core-systems, dashboard, agents, gpu-tests, slate-live-system, ml-pipeline, package]
    if: always()
    timeout-minutes: 5
    steps:
      - name: Prepare Workspace
        shell: pwsh
        run: |
          if (-not (Test-Path "${{ github.workspace }}")) {
            New-Item -ItemType Directory -Path "${{ github.workspace }}" -Force | Out-Null
          }

      - uses: actions/checkout@v4
        with:
          clean: true

      - name: Generate Summary
        shell: pwsh
        run: |
          $python = if (Test-Path ".venv\Scripts\python.exe") { ".venv\Scripts\python.exe" } else { "python" }
          Write-Host ""
          Write-Host "========================================" -ForegroundColor Cyan
          Write-Host "  SLATE Self-Hosted Runner Summary" -ForegroundColor Cyan
          Write-Host "========================================" -ForegroundColor Cyan
          Write-Host ""
          Write-Host "Environment:    ${{ needs.environment.result }}"
          Write-Host "Core Systems:   ${{ needs.core-systems.result }}"
          Write-Host "Dashboard:      ${{ needs.dashboard.result }}"
          Write-Host "Agents:         ${{ needs.agents.result }}"
          Write-Host "GPU Tests:      ${{ needs.gpu-tests.result }}"
          Write-Host "SLATE Live:     ${{ needs.slate-live-system.result }}"
          Write-Host "ML Pipeline:    ${{ needs.ml-pipeline.result }}"
          Write-Host "Package:        ${{ needs.package.result }}"
          Write-Host ""
          Write-Host "SDK Version:    ${{ needs.environment.outputs.slate_version }}"
          Write-Host "GPU Count:      ${{ needs.environment.outputs.gpu_count }}"
          Write-Host ""

      - name: Write Job Summary
        shell: pwsh
        run: |
          $summary = @"
          ## SLATE Self-Hosted Runner Report

          | System | Status |
          |--------|--------|
          | Environment | ${{ needs.environment.result }} |
          | Core Systems | ${{ needs.core-systems.result }} |
          | Dashboard & API | ${{ needs.dashboard.result }} |
          | Agent System | ${{ needs.agents.result }} |
          | GPU Tests (Dual) | ${{ needs.gpu-tests.result }} |
          | **SLATE Live System** | **${{ needs.slate-live-system.result }}** |
          | ML Pipeline | ${{ needs.ml-pipeline.result }} |
          | Package & Build | ${{ needs.package.result }} |

          **SDK Version:** ${{ needs.environment.outputs.slate_version }}
          **GPUs:** ${{ needs.environment.outputs.gpu_count }} (Dual-GPU)
          **Runner:** ``self-hosted, slate, gpu, multi-gpu, windows``
          "@
          $summary | Out-File -FilePath $env:GITHUB_STEP_SUMMARY -Encoding utf8 -Append
