# Modified: 2026-02-07T18:30:00Z | Author: COPILOT | Change: Add matrix strategies for test suites and transformer analysis
name: SLATE Nightly

on:
  schedule:
    - cron: '0 4 * * *'
  workflow_dispatch:

concurrency:
  group: nightly-${{ github.ref }}
  cancel-in-progress: false  # Let nightly runs complete

permissions:
  contents: read

defaults:
  run:
    shell: powershell

jobs:
  full-test-suite:
    name: Tests (${{ matrix.suite }})
    runs-on: [self-hosted, slate]
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        suite:
          - core
          - security
          - agents
          - ml
        include:
          - suite: core
            pattern: 'test_slate_runtime or test_slate_workflow or test_feature_flags or test_install_tracker or test_slate_benchmark or test_watcher or test_module_registry or test_slate_terminal_monitor or test_runner_cost_tracker or test_runner_fallback'
          - suite: security
            pattern: 'test_pii_scanner or test_action_guard or test_sdk_source_guard or test_slate_workflow_analyzer'
          - suite: agents
            pattern: 'test_agent_registry or test_agent_plugins or test_slate_runner_manager or test_slate_runner_benchmark or test_slate_real_multi_runner or test_copilot_slate_runner or test_slate_discussion_manager or test_slate_project_board'
          - suite: ml
            pattern: 'test_ml_orchestrator or test_slate_model_trainer or test_slate_gpu_manager or test_slate_warmup or test_slate_unified_autonomous or test_integrated_autonomous_loop or test_slate_hardware_optimizer'
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Install test deps
        run: pip install pytest pytest-cov pytest-asyncio --quiet 2>$null
        continue-on-error: true
      - name: Run ${{ matrix.suite }} tests with coverage
        run: python -m pytest tests/ -v -k "${{ matrix.pattern }}" --tb=long --cov=slate --cov-report=term-missing
        continue-on-error: true

  slate-health:
    name: SLATE Health
    runs-on: [self-hosted, slate]
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: SLATE status
        run: python slate/slate_status.py --quick
      - name: Validate task queue
        run: |
          python -c @"
          import json, pathlib
          p = pathlib.Path('current_tasks.json')
          if p.exists():
              data = json.loads(p.read_text())
              tasks = data.get('tasks', data) if isinstance(data, dict) else data
              print(f'Task queue: {len(tasks)} tasks')
              for t in tasks[:5]:
                  status = t.get('status', 'unknown')
                  title = t.get('title', t.get('name', 'unnamed'))
                  print(f'  [{status}] {title}')
          else:
              print('No task queue found')
          "@

  sdk-import-audit:
    name: SDK Import Audit
    runs-on: [self-hosted, slate]
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Audit all modules
        run: |
          python -c @"
          import importlib, pathlib, sys
          ok, fail = [], []
          for f in sorted(pathlib.Path('slate').glob('*.py')):
              mod = f.stem
              if mod.startswith('_'): continue
              try:
                  importlib.import_module(f'slate.{mod}')
                  ok.append(mod)
                  print(f'  OK: slate.{mod}')
              except Exception as e:
                  fail.append((mod, str(e)))
                  print(f'  FAIL: slate.{mod}: {e}')
          print(f'Audit: {len(ok)} OK, {len(fail)} failed')
          if fail: sys.exit(1)
          "@

  dependency-check:
    name: Dependency Check
    runs-on: [self-hosted, slate]
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Check outdated packages
        run: pip list --outdated 2>$null | Select-Object -First 20
        continue-on-error: true
      - name: Validate requirements
        run: |
          python -c @"
          import pathlib
          req = pathlib.Path('requirements.txt')
          if req.exists():
              lines = [l.strip() for l in req.read_text().splitlines() if l.strip() and not l.startswith('#')]
              print(f'Requirements: {len(lines)} packages')
              for l in lines[:10]:
                  print(f'  {l}')
          "@

  ai-codebase-analysis:
    name: AI Codebase Analysis
    runs-on: [self-hosted, slate, gpu, gpu-2]
    timeout-minutes: 60
    env:
      CUDA_VISIBLE_DEVICES: '0,1'
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Check Ollama
        id: ollama
        run: |
          $available = $false
          try {
            $response = Invoke-RestMethod -Uri "http://127.0.0.1:11434/api/tags" -TimeoutSec 5
            if ($response) { $available = $true }
          } catch { }
          "available=$available" | Out-File -Append $env:GITHUB_OUTPUT
      - name: Warmup AI Models
        if: steps.ollama.outputs.available == 'True'
        run: |
          python slate/slate_ai_orchestrator.py --warmup
      - name: Full Codebase Analysis
        if: steps.ollama.outputs.available == 'True'
        run: |
          Write-Host "Running AI-powered codebase analysis..."
          Write-Host ""
          python slate/slate_ai_orchestrator.py --analyze-codebase --json > codebase_analysis.json

          $analysis = Get-Content codebase_analysis.json -Raw | ConvertFrom-Json
          Write-Host "Files analyzed: $($analysis.total_files)"
          Write-Host "Code quality: $($analysis.code_quality)"

          "## AI Codebase Analysis" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "**Files Analyzed**: $($analysis.total_files)" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "**Code Quality**: $($analysis.code_quality)" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "**Recommendations**: $($analysis.recommendations_count)" | Out-File -Append $env:GITHUB_STEP_SUMMARY
      - name: Update Documentation (if needed)
        if: steps.ollama.outputs.available == 'True'
        run: |
          python slate/slate_ai_orchestrator.py --update-docs
        continue-on-error: true
      - name: Upload Analysis
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-codebase-analysis
          path: codebase_analysis.json
          retention-days: 30
          if-no-files-found: ignore

  # ------------ Nightly Transformer Analysis (Matrix) ------------
  transformer-nightly:
    name: Transformer (${{ matrix.task }})
    runs-on: [self-hosted, slate, gpu, gpu-2]
    timeout-minutes: 20
    env:
      CUDA_VISIBLE_DEVICES: '0,1'
    strategy:
      fail-fast: false
      matrix:
        task:
          - security-scan
          - benchmark
          - commit-history
        include:
          - task: security-scan
            script: >-
              python -c "
              from slate.slate_transformers import SlateTransformerPipeline;
              import json, pathlib;
              p = SlateTransformerPipeline();
              results = [];
              for f in sorted(pathlib.Path('slate').glob('*.py'))[:10]:
                code = f.read_text(encoding='utf-8')[:2000];
                r = p.security_scan(code);
                results.append({'file': str(f), 'scan': r});
              print(json.dumps({'scanned': len(results), 'results': results}, indent=2))
              "
          - task: benchmark
            script: 'python slate/slate_transformers.py --benchmark --json'
          - task: commit-history
            script: >-
              python -c "
              from slate.slate_transformers import SlateTransformerPipeline;
              import json, subprocess;
              log = subprocess.run(['git', 'log', '--max-count=20', '--pretty=format:%s'],
                capture_output=True, text=True).stdout.strip().split('\n');
              p = SlateTransformerPipeline();
              r = p.classify_commits(log);
              print(json.dumps(r, indent=2))
              "
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Run ${{ matrix.task }}
        run: ${{ matrix.script }}
        continue-on-error: true

  summary:
    name: Nightly Summary
    runs-on: [self-hosted, slate]
    needs: [full-test-suite, slate-health, sdk-import-audit, dependency-check, ai-codebase-analysis, transformer-nightly]
    if: always()
    steps:
      - name: Generate summary
        run: |
          "## Nightly Health Summary" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Check | Status |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "|-------|--------|" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Full Tests (matrix) | ${{ needs.full-test-suite.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| SLATE Health | ${{ needs.slate-health.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| SDK Import Audit | ${{ needs.sdk-import-audit.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Dependency Check | ${{ needs.dependency-check.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| AI Analysis | ${{ needs.ai-codebase-analysis.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "| Transformer Analysis (matrix) | ${{ needs.transformer-nightly.result }} |" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          "Run at $(Get-Date -Format 'yyyy-MM-dd HH:mm UTC')" | Out-File -Append $env:GITHUB_STEP_SUMMARY
