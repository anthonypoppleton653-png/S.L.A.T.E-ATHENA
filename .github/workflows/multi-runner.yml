# Modified: 2026-02-07T04:56:45Z | Author: COPILOT | Change: Normalize paths and clean workflow artifacts
# S.L.A.T.E. Multi-Runner Parallel Proof Workflow
# Proves REAL parallel execution across 4 registered runner instances with GPU compute
# Modified: 2026-02-07T02:00:00Z | Author: COPILOT | Change: Added real GPU compute to GPU jobs

name: Multi-Runner Parallel Proof

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'Execution mode'
        required: true
        default: 'parallel-proof'
        type: choice
        options:
          - parallel-proof
          - full-suite

concurrency:
  group: multi-runner-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

# All 4 jobs launch simultaneously - each targets a DIFFERENT runner via labels
jobs:
  # ------------ JOB 1: slate-runner (primary, has cuda label) ------------
  job-runner-1:
    name: 'Runner 1: SDK Validation'
    runs-on: [self-hosted, slate, cuda]
    defaults:
      run:
        shell: powershell
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Record start
        run: |
          Write-Host "JOB START: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"
      - name: SDK Validation
        run: |
          python -c "import slate; print(f'SLATE v{slate.__version__}')"
          python -c "from slate.slate_status import main; print('Status module OK')"
          python -c "from slate.slate_real_multi_runner import RealMultiRunnerManager; print('Real Multi-runner module OK')"
          python -c "from agents.runner_api import RunnerAPI; print('RunnerAPI OK')"
      - name: GPU Check
        run: |
          nvidia-smi --query-gpu=index,name,memory.total --format=csv,noheader
      - name: GPU Compute - SDK + CUDA Validation
        run: |
          python tests/test_gpu_compute.py
      - name: Record end
        run: |
          Write-Host "JOB END: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"

  # ------------ JOB 2: slate-runner-2 (GPU 0 label) ------------
  job-runner-2:
    name: 'Runner 2: Tests GPU 0'
    runs-on: [self-hosted, slate, gpu-0]
    defaults:
      run:
        shell: powershell
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Record start
        run: |
          Write-Host "JOB START: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"
      - name: Tests (GPU 0)
        env:
          CUDA_VISIBLE_DEVICES: '0'
        run: |
          python -m pytest tests/ -v --tb=short -x -k "not integration" 2>&1 | Select-Object -First 30
        continue-on-error: true
      - name: GPU 0 Compute Benchmark
        env:
          CUDA_VISIBLE_DEVICES: '0'
        run: |
          python tests/test_gpu_compute.py
      - name: Record end
        run: |
          Write-Host "JOB END: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"

  # ------------ JOB 3: slate-runner-3 (GPU 1 label) ------------
  job-runner-3:
    name: 'Runner 3: Tests GPU 1'
    runs-on: [self-hosted, slate, gpu-1]
    defaults:
      run:
        shell: powershell
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Record start
        run: |
          Write-Host "JOB START: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"
      - name: GPU 1 Compute Benchmark
        env:
          CUDA_VISIBLE_DEVICES: '1'
        run: |
          python tests/test_gpu_compute.py
      - name: Embedding Generation Test
        env:
          CUDA_VISIBLE_DEVICES: '1'
        run: |
          python -c "import torch; dev=torch.device('cuda:0'); e=torch.randn(64,512,768,device=dev); w=torch.randn(768,768,device=dev); torch.cuda.synchronize(); import time; t=time.perf_counter(); p=torch.matmul(e,w); p=torch.nn.functional.normalize(p,dim=-1); torch.cuda.synchronize(); print(f'Embedding: {(time.perf_counter()-t)*1000:.1f}ms, shape={p.shape}'); del e,w,p; torch.cuda.empty_cache()"
      - name: Benchmark
        run: |
          python slate/slate_benchmark.py 2>&1 | Select-Object -First 20
        continue-on-error: true
      - name: Record end
        run: |
          Write-Host "JOB END: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"

  # ------------ JOB 4: slate-runner-4 (CPU only label) ------------
  job-runner-4:
    name: 'Runner 4: Lint & Security'
    runs-on: [self-hosted, slate, cpu-only]
    defaults:
      run:
        shell: powershell
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Record start
        run: |
          Write-Host "JOB START: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"
      - name: Lint
        run: |
          python -m ruff check slate/ agents/ --output-format=text 2>&1 | Select-Object -First 20
        continue-on-error: true
      - name: Security scan
        run: |
          python -c "from slate.pii_scanner import PIIScanner; s=PIIScanner(); print('PII Scanner OK')"
          python -c "from slate.action_guard import ActionGuard; print('Action Guard OK')"
        continue-on-error: true
      - name: Record end
        run: |
          Write-Host "JOB END: $(Get-Date -Format 'HH:mm:ss.fff')"
          Write-Host "RUNNER: $env:RUNNER_NAME"

  # ------------ SUMMARY: Proves all 4 ran on different runners ------------
  summary:
    name: 'Parallel Proof Summary'
    runs-on: [self-hosted, slate]
    needs: [job-runner-1, job-runner-2, job-runner-3, job-runner-4]
    if: always()
    defaults:
      run:
        shell: powershell
    steps:
      - uses: actions/checkout@v6
      - name: Setup Python
        run: |
          "$env:GITHUB_WORKSPACE\\.venv\\Scripts" | Out-File -Append $env:GITHUB_PATH
      - name: Multi-Runner Status
        run: |
          python slate/slate_real_multi_runner.py --status
      - name: Generate Summary
        run: |
          Write-Host "============================================"
          Write-Host "  MULTI-RUNNER PARALLEL PROOF COMPLETE"
          Write-Host "============================================"
          Write-Host ""
          Write-Host "Job Results:"
          Write-Host "  Runner 1 (SDK):      ${{ needs.job-runner-1.result }}"
          Write-Host "  Runner 2 (GPU 0):    ${{ needs.job-runner-2.result }}"
          Write-Host "  Runner 3 (GPU 1):    ${{ needs.job-runner-3.result }}"
          Write-Host "  Runner 4 (CPU):      ${{ needs.job-runner-4.result }}"
          Write-Host ""
          Write-Host "All 4 jobs ran on SEPARATE runner instances"
          Write-Host "with DIFFERENT labels targeting DIFFERENT hardware."
          Write-Host "============================================"
