# Modified: 2026-02-08T12:00:00Z | Author: Claude Opus 4.5 | Change: Create comprehensive SLATE Dashboard K8s deployment with full integrations
# Modified: 2026-02-09T07:20:00Z | Author: COPILOT | Change: Use slate:local image with IfNotPresent pull policy for local K8s deployment
# SLATE Dashboard - Full FastAPI UI with SLATE System Integrations
# Replaces the stub slate-core deployment with production-ready dashboard
---
# ─────────────────────────────────────────────────────────────────────────────
# ConfigMap: Dashboard Configuration
# Contains all SLATE integration settings and feature flags
# ─────────────────────────────────────────────────────────────────────────────
apiVersion: v1
kind: ConfigMap
metadata:
  name: slate-dashboard-config
  namespace: slate
  labels:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
    app.kubernetes.io/part-of: slate-system
data:
  # Server configuration
  SLATE_DASHBOARD_HOST: "0.0.0.0"
  SLATE_DASHBOARD_PORT: "8080"
  SLATE_LOG_LEVEL: "INFO"

  # SLATE integrations (K8s service DNS)
  OLLAMA_HOST: "ollama-svc:11434"
  CHROMADB_HOST: "chromadb-svc:8000"

  # Feature flags
  SLATE_ENABLE_WEBSOCKET: "true"
  SLATE_ENABLE_GPU_MONITORING: "true"
  SLATE_ENABLE_WORKFLOW_DISPATCH: "true"
  SLATE_ENABLE_TASK_QUEUE: "true"
  SLATE_ENABLE_SCHEMATIC_API: "true"
  SLATE_ENABLE_INTERACTIVE_API: "true"

  # UI theme settings
  SLATE_THEME: "watchmaker"
  SLATE_GLASS_OPACITY: "0.75"

  # GitHub integration
  GITHUB_OWNER: "SynchronizedLivingArchitecture"
  GITHUB_REPO: "S.L.A.T.E"

  # Kubernetes-specific settings
  SLATE_K8S: "true"
  SLATE_MODE: "prod"
  SLATE_TECH_TREE_PATH: "/app/.slate_tech_tree/tech_tree.json"

---
# ─────────────────────────────────────────────────────────────────────────────
# ConfigMap: Dashboard Startup Script
# Python entrypoint that handles K8s-specific initialization
# ─────────────────────────────────────────────────────────────────────────────
apiVersion: v1
kind: ConfigMap
metadata:
  name: slate-dashboard-entrypoint
  namespace: slate
  labels:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
data:
  start-dashboard.py: |
    #!/usr/bin/env python3
    """
    SLATE Dashboard K8s Entrypoint
    Handles service discovery and initialization in Kubernetes environment.
    """
    import os
    import sys
    import time
    import urllib.request
    import urllib.error

    def wait_for_service(url: str, name: str, timeout: int = 60) -> bool:
        """Wait for a service to become available."""
        print(f"[*] Waiting for {name} at {url}...")
        start = time.time()
        while time.time() - start < timeout:
            try:
                req = urllib.request.Request(url, method="GET")
                with urllib.request.urlopen(req, timeout=5) as resp:
                    if resp.status == 200:
                        print(f"[+] {name} is ready")
                        return True
            except Exception:
                pass
            time.sleep(2)
        print(f"[-] {name} timeout after {timeout}s (continuing anyway)")
        return False

    def main():
        # Wait for dependent services (optional - dashboard can run without them)
        ollama_host = os.environ.get("OLLAMA_HOST", "http://ollama-svc:11434")
        chroma_host = os.environ.get("CHROMADB_HOST", "http://chromadb-svc:8000")

        # Non-blocking service checks
        wait_for_service(f"{ollama_host}/api/tags", "Ollama", timeout=30)
        wait_for_service(f"{chroma_host}/api/v2/heartbeat", "ChromaDB", timeout=15)

        # Set up Python path
        workspace = os.environ.get("SLATE_WORKSPACE", "/workspace")
        sys.path.insert(0, workspace)
        sys.path.insert(0, os.path.join(workspace, "slate"))

        # Import and run dashboard
        os.chdir(workspace)

        # Copy tech tree to expected location (workspace may be read-only)
        tech_tree_src = os.environ.get("SLATE_TECH_TREE_PATH")
        if tech_tree_src and os.path.exists(tech_tree_src):
            import shutil
            tech_tree_dir = "/tmp/.slate_tech_tree"
            os.makedirs(tech_tree_dir, exist_ok=True)
            dest = os.path.join(tech_tree_dir, "tech_tree.json")
            shutil.copy2(tech_tree_src, dest)
            # Update environment so dashboard finds it
            os.environ["SLATE_WORKSPACE_TECH_TREE"] = dest
            print(f"[+] Copied tech tree to {dest}")

        try:
            import uvicorn
            from agents.slate_dashboard_server import app
            from fastapi.responses import JSONResponse

            # Override tech-tree endpoint to use ConfigMap-mounted file
            tech_tree_file = os.environ.get("SLATE_TECH_TREE_PATH")
            if tech_tree_file and os.path.exists(tech_tree_file):
                # Remove existing route first
                for route in list(app.routes):
                    if hasattr(route, 'path') and route.path == "/api/tech-tree":
                        app.routes.remove(route)
                        break

                @app.get("/api/tech-tree")
                async def api_tech_tree_k8s():
                    import json as _json
                    try:
                        with open(tech_tree_file, "r", encoding="utf-8") as f:
                            data = _json.load(f)
                        nodes = data.get("nodes", [])
                        edges = data.get("edges", [])
                        by_status = {}
                        for node in nodes:
                            status = node.get("status", "unknown")
                            by_status[status] = by_status.get(status, 0) + 1
                        return JSONResponse(content={
                            "nodes": nodes, "edges": edges,
                            "metadata": data.get("metadata", {}),
                            "version": data.get("version", "1.0.0"),
                            "total": len(nodes), "by_status": by_status
                        })
                    except Exception as e:
                        return JSONResponse(content={"nodes": [], "edges": [], "error": str(e)})
                print(f"[+] Tech tree API overridden with: {tech_tree_file}")

            host = os.environ.get("SLATE_DASHBOARD_HOST", "0.0.0.0")
            port = int(os.environ.get("SLATE_DASHBOARD_PORT", "8080"))

            print(f"[+] Starting SLATE Dashboard on {host}:{port}")
            print(f"[+] Ollama: {ollama_host}")
            print(f"[+] ChromaDB: {chroma_host}")
            print(f"[+] Kubernetes mode: {os.environ.get('SLATE_K8S', 'false')}")

            uvicorn.run(
                app,
                host=host,
                port=port,
                log_level=os.environ.get("SLATE_LOG_LEVEL", "info").lower(),
                access_log=True,
            )
        except ImportError as e:
            print(f"[-] Import error: {e}")
            print("[*] Falling back to basic health server...")

            # Fallback: simple HTTP server for health checks
            import http.server
            import json

            class HealthHandler(http.server.BaseHTTPRequestHandler):
                def do_GET(self):
                    self.send_response(200)
                    self.send_header("Content-Type", "application/json")
                    self.end_headers()
                    self.wfile.write(json.dumps({
                        "status": "degraded",
                        "component": "slate-dashboard",
                        "error": str(e),
                        "message": "Dashboard dependencies not available"
                    }).encode())

                def log_message(self, *args):
                    pass

            port = int(os.environ.get("SLATE_DASHBOARD_PORT", "8080"))
            server = http.server.HTTPServer(("0.0.0.0", port), HealthHandler)
            print(f"[*] Health server running on :{port}")
            server.serve_forever()

    if __name__ == "__main__":
        main()

---
# ─────────────────────────────────────────────────────────────────────────────
# Deployment: SLATE Dashboard
# Full FastAPI dashboard with all SLATE integrations
# ─────────────────────────────────────────────────────────────────────────────
apiVersion: apps/v1
kind: Deployment
metadata:
  name: slate-dashboard
  namespace: slate
  labels:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
    app.kubernetes.io/part-of: slate-system
  annotations:
    slate.io/description: "Full SLATE Dashboard with WebSocket, GPU monitoring, and all integrations"
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app.kubernetes.io/name: slate-dashboard
      app.kubernetes.io/component: dashboard
  template:
    metadata:
      labels:
        app.kubernetes.io/name: slate-dashboard
        app.kubernetes.io/component: dashboard
        app.kubernetes.io/part-of: slate-system
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: slate-core
      automountServiceAccountToken: false

      # Pod-level security context
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault

      # Init container: wait for Ollama
      initContainers:
        - name: wait-for-ollama
          image: busybox:1.36
          command: ['sh', '-c']
          args:
            - |
              echo "Waiting for Ollama..."
              until wget -q --spider http://ollama-svc:11434/api/tags 2>/dev/null; do
                echo "Ollama not ready, waiting..."
                sleep 5
              done
              echo "Ollama is ready!"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]

      containers:
        - name: dashboard
          image: slate:local
          imagePullPolicy: IfNotPresent

          # Run the full dashboard server
          command: ["python"]
          args:
            - "/entrypoint/start-dashboard.py"

          ports:
            - name: http
              containerPort: 8080
              protocol: TCP

          # Environment from ConfigMap
          envFrom:
            - configMapRef:
                name: slate-dashboard-config

          # Additional environment variables
          env:
            - name: SLATE_WORKSPACE
              value: /workspace
            - name: PYTHONPATH
              # Modified: 2026-02-09T00:00:00Z | Author: COPILOT | Change: Fix PYTHONPATH to match Dockerfile base /slate
              value: /slate:/workspace
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            # GitHub token from secret (optional)
            - name: GITHUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: slate-github-secret
                  key: token
                  optional: true

          # Container-level security
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: false
            capabilities:
              drop:
                - ALL

          # Resource limits
          resources:
            requests:
              cpu: 250m
              memory: 512Mi
            limits:
              cpu: 1000m
              memory: 2Gi

          # Volume mounts
          volumeMounts:
            - name: workspace
              mountPath: /workspace
              readOnly: true
            - name: entrypoint
              mountPath: /entrypoint
              readOnly: true
            - name: tmp
              mountPath: /tmp
            - name: cache
              mountPath: /home/slate/.cache
            - name: tech-tree
              mountPath: /app/.slate_tech_tree
              readOnly: true

          # Health probes
          startupProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 30
            timeoutSeconds: 5

          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3

          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 3

      volumes:
        - name: workspace
          persistentVolumeClaim:
            claimName: slate-workspace-pvc
        - name: entrypoint
          configMap:
            name: slate-dashboard-entrypoint
            defaultMode: 0755
        - name: tmp
          emptyDir:
            sizeLimit: 500Mi
        - name: cache
          emptyDir:
            sizeLimit: 200Mi
        - name: tech-tree
          configMap:
            name: slate-tech-tree

      # Topology spread for high availability
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: slate-dashboard

---
# ─────────────────────────────────────────────────────────────────────────────
# Service: SLATE Dashboard
# ClusterIP service for internal access + Ingress routing
# ─────────────────────────────────────────────────────────────────────────────
apiVersion: v1
kind: Service
metadata:
  name: slate-dashboard-svc
  namespace: slate
  labels:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
    app.kubernetes.io/part-of: slate-system
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
  ports:
    - name: http
      port: 8080
      targetPort: 8080
      protocol: TCP
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600

---
# ─────────────────────────────────────────────────────────────────────────────
# HorizontalPodAutoscaler: Dashboard Auto-scaling
# Scales based on CPU and memory utilization
# ─────────────────────────────────────────────────────────────────────────────
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: slate-dashboard-hpa
  namespace: slate
  labels:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: slate-dashboard
  minReplicas: 2
  maxReplicas: 6
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
        - type: Pods
          value: 2
          periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Pods
          value: 1
          periodSeconds: 120

---
# ─────────────────────────────────────────────────────────────────────────────
# PodDisruptionBudget: Dashboard High Availability
# Ensures at least 1 replica is always available
# ─────────────────────────────────────────────────────────────────────────────
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: slate-dashboard-pdb
  namespace: slate
  labels:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: slate-dashboard
      app.kubernetes.io/component: dashboard

---
# ─────────────────────────────────────────────────────────────────────────────
# NetworkPolicy: Dashboard Network Rules
# Allows ingress from nginx-ingress and egress to SLATE services
# ─────────────────────────────────────────────────────────────────────────────
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: slate-dashboard-network
  namespace: slate
  labels:
    app.kubernetes.io/name: slate-dashboard
    app.kubernetes.io/component: dashboard
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: slate-dashboard
  policyTypes:
    - Ingress
    - Egress
  ingress:
    # Allow from ingress controller
    - from:
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: ingress-nginx
      ports:
        - protocol: TCP
          port: 8080
    # Allow from within slate namespace (other SLATE services)
    - from:
        - podSelector:
            matchLabels:
              app.kubernetes.io/part-of: slate-system
      ports:
        - protocol: TCP
          port: 8080
  egress:
    # Allow to Ollama
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: ollama
      ports:
        - protocol: TCP
          port: 11434
    # Allow to ChromaDB
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: chromadb
      ports:
        - protocol: TCP
          port: 8000
    # Allow DNS
    - to:
        - namespaceSelector: {}
          podSelector:
            matchLabels:
              k8s-app: kube-dns
      ports:
        - protocol: UDP
          port: 53
    # Allow GitHub API (for workflow dispatch)
    - to:
        - ipBlock:
            cidr: 0.0.0.0/0
      ports:
        - protocol: TCP
          port: 443
